# TECHNOTES002 â€” Flutter + Native (Kotlin/Swift) Real-time YOLO11
Hereâ€™s a tightened but more technical version that explains how each goal is achieved, while staying brief and naming the key frameworks ðŸ‘‡


# Architecture & execution model
	â€¢	3 execution paths: Flutter (bridge), Native Android (Kotlin), Native iOS (Swift) to validate parity across stacks.
	â€¢	Flutter acts as orchestrator only; camera capture and inference live fully in native layers.
	â€¢	Bounding boxes are produced in normalized space (0â€“1) and mapped to preview size in the overlay layer to avoid recomputation.

# Camera, inference & threading
	â€¢	Android (Kotlin)
	â€¢	CameraX ImageAnalysis with STRATEGY_KEEP_ONLY_LATEST
	â€¢	Single-threaded executor + AtomicBoolean gate to prevent frame backlog
	â€¢	TFLite Interpreter reused across frames, zero per-frame allocations
	â€¢	iOS (Swift)
	â€¢	AVFoundation capture pipeline
	â€¢	CoreML via VNCoreMLRequest on a background queue
	â€¢	Late frames dropped when inference is in-flight; UI updated on main thread only
	â€¢	Flutter bridge
	â€¢	Platform channels deliver structured results
	â€¢	Dart side coalesces updates to prevent layout thrash and UI jank

# Overlay & rendering
	â€¢	Overlays are decoupled from inference timing
	â€¢	Rectangles rendered from normalized boxes â†’ view coordinates
	â€¢	Rendering uses lightweight Canvas / Core Graphics primitives only

# Lifecycle, safety & error handling
	â€¢	Permission gating handled before pipeline startup (CameraX / AVAuthorizationStatus)
	â€¢	Native cleanup is explicit:
	â€¢	Android: ImageProxy.close(), executor shutdown, interpreter close
	â€¢	iOS: stop capture session, release CoreML/Vision requests
	â€¢	Missing or mis-bundled models surface clear runtime errors, never crashes

# Production-scale considerations
	â€¢	Dynamic model & resolution scaling based on FPS and thermal state
	â€¢	Structured performance logging (latency, FPS) with no PII
	â€¢	Aspect-ratio & orientationâ€“safe box mapping tests
	â€¢	Defensive parsing for CoreML MLMultiArray outputs when Vision metadata is absent

